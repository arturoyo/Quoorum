# üìä Sistema de Logging Propio de Quoorum

Sistema de logging completamente independiente que almacena logs en Supabase sin depender de servicios de terceros como Sentry o PostHog.

## ‚ú® Caracter√≠sticas

- ‚úÖ **Almacenamiento propio** - Logs en Supabase PostgreSQL
- ‚úÖ **Sin costos externos** - No dependemos de Sentry/PostHog
- ‚úÖ **Privacidad total** - Tus datos nunca salen de tu infraestructura
- ‚úÖ **Batch processing** - Alta performance con inserciones por lotes
- ‚úÖ **Dashboard completo** - Visualiza y filtra logs en tiempo real
- ‚úÖ **Auto-captura de errores** - Frontend captura errores no manejados autom√°ticamente
- ‚úÖ **B√∫squeda avanzada** - Filtra por nivel, source, usuario, fecha
- ‚úÖ **Exportaci√≥n** - Descarga logs en CSV
- ‚úÖ **Limpieza autom√°tica** - Elimina logs antiguos para ahorrar espacio

## üìã Niveles de Log

| Nivel   | Uso                                    | Color    |
| ------- | -------------------------------------- | -------- |
| `debug` | Informaci√≥n detallada para debugging   | Gris     |
| `info`  | Informaci√≥n general del sistema        | Azul     |
| `warn`  | Advertencias que no son errores        | Amarillo |
| `error` | Errores manejables                     | Rojo     |
| `fatal` | Errores cr√≠ticos que requieren acci√≥n  | P√∫rpura  |

## üöÄ Uso en Backend (API/Workers)

```typescript
import { systemLogger } from '@quoorum/api/lib/system-logger'

// INFO: Operaciones exitosas
systemLogger.info('Usuario creado exitosamente', { userId: '123' })

// WARN: Advertencias
systemLogger.warn('Rate limit cercano', { userId: '123', usage: 95 })

// ERROR: Errores con stack trace
try {
  await createUser(data)
} catch (error) {
  systemLogger.error('Error al crear usuario', error as Error, {
    userId: '123',
    data: { email: data.email }
  })
}

// FATAL: Errores cr√≠ticos (flush inmediato)
systemLogger.fatal('Database connection lost', error)

// PERFORMANCE: Medir duraci√≥n de operaciones
const result = await systemLogger.measure(
  'Process payment',
  async () => await processPayment(orderId),
  { orderId, userId }
)
```

### Configurar Source y UserId

```typescript
// Worker
systemLogger.setSource('worker')
systemLogger.setUserId(null)

// Con contexto espec√≠fico
const workerLogger = systemLogger.withContext({
  source: 'worker',
  userId: null
})

workerLogger.info('Job started', { jobId: '456' })
```

## üåê Uso en Frontend (React/Next.js)

```typescript
import { logger } from '@/lib/logger'

// INFO: Eventos normales
logger.info('Debate created', { debateId: '123' })

// TRACK: Analytics events
logger.track('button_clicked', { buttonId: 'create-debate' })

// ERROR: Errores con contexto
try {
  await api.debates.create.mutate(data)
} catch (error) {
  logger.error('Failed to create debate', error as Error, { data })
}

// Los errores no manejados se capturan autom√°ticamente
```

### Auto-captura de Errores

El cliente captura autom√°ticamente:
- ‚úÖ `window.onerror` - Errores globales no manejados
- ‚úÖ `window.onunhandledrejection` - Promesas sin catch
- ‚úÖ `window.onbeforeunload` - Flush antes de cerrar la p√°gina

## üéØ Dashboard de Admin

Accede al dashboard en: **http://localhost:3002/admin/logs**

### Caracter√≠sticas del Dashboard:

1. **Estad√≠sticas en tiempo real**
   - Total de logs
   - Logs por nivel (debug, info, warn, error, fatal)
   - Logs por source (client, server, worker, cron)

2. **Filtros avanzados**
   - Por nivel (debug, info, warn, error, fatal)
   - Por source (client, server, worker, cron)
   - Por usuario (userId)
   - B√∫squeda en mensajes
   - Rango de fechas

3. **Acciones**
   - Refrescar logs en tiempo real
   - Exportar a CSV
   - Limpiar logs antiguos (+30 d√≠as)

4. **Vista expandible**
   - Click en un log para ver detalles completos
   - Stack traces de errores
   - Metadata JSON completo

## üìä Schema de la Tabla

```sql
CREATE TABLE system_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE SET NULL,

  -- Metadata
  level log_level NOT NULL,
  source log_source NOT NULL,
  message TEXT NOT NULL,

  -- Context
  metadata JSONB,

  -- Error details
  error_name VARCHAR(255),
  error_message TEXT,
  error_stack TEXT,

  -- Performance
  duration_ms JSONB,

  -- Timestamps
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() NOT NULL
);

-- √çndices para b√∫squeda r√°pida
CREATE INDEX system_logs_user_id_idx ON system_logs(user_id);
CREATE INDEX system_logs_level_idx ON system_logs(level);
CREATE INDEX system_logs_source_idx ON system_logs(source);
CREATE INDEX system_logs_created_at_idx ON system_logs(created_at);
CREATE INDEX system_logs_user_level_created_idx ON system_logs(user_id, level, created_at);
```

## üîÑ Batch Processing

Los logs se procesan por lotes para optimizar performance:

### Backend
- **Max batch size:** 50 logs
- **Interval:** 5 segundos
- **Flush inmediato:** Errores cr√≠ticos (error/fatal)

### Frontend
- **Max batch size:** 20 logs
- **Interval:** 10 segundos
- **Flush inmediato:** Errores cr√≠ticos + beforeunload

## üßπ Limpieza Autom√°tica

```typescript
// Manual: Eliminar logs > 30 d√≠as
const result = await api.systemLogs.deleteOld.mutate({
  olderThanDays: 30
})

console.log(`Eliminados ${result.deletedCount} logs`)
```

### Worker Autom√°tico (Recomendado)

Crear un cron job que ejecute limpieza diaria:

```typescript
// packages/workers/src/functions/cleanup-logs.ts
import { inngest } from '../inngest'
import { db } from '@quoorum/db'
import { systemLogs } from '@quoorum/db/schema'
import { lte } from 'drizzle-orm'

export const cleanupLogs = inngest.createFunction(
  { id: 'cleanup-logs' },
  { cron: '0 2 * * *' }, // Diario a las 2 AM
  async () => {
    const cutoffDate = new Date()
    cutoffDate.setDate(cutoffDate.getDate() - 30)

    const deleted = await db
      .delete(systemLogs)
      .where(lte(systemLogs.createdAt, cutoffDate))
      .returning({ id: systemLogs.id })

    return { deletedCount: deleted.length }
  }
)
```

## üìà An√°lisis y Queries

### Logs m√°s frecuentes

```sql
SELECT message, COUNT(*) as count
FROM system_logs
WHERE created_at > NOW() - INTERVAL '1 day'
GROUP BY message
ORDER BY count DESC
LIMIT 10;
```

### Errores por usuario

```sql
SELECT user_id, COUNT(*) as error_count
FROM system_logs
WHERE level IN ('error', 'fatal')
  AND created_at > NOW() - INTERVAL '7 days'
GROUP BY user_id
ORDER BY error_count DESC
LIMIT 10;
```

### Performance promedio por operaci√≥n

```sql
SELECT
  message,
  AVG((metadata->>'durationMs')::numeric) as avg_duration_ms,
  COUNT(*) as count
FROM system_logs
WHERE metadata ? 'durationMs'
  AND created_at > NOW() - INTERVAL '1 day'
GROUP BY message
ORDER BY avg_duration_ms DESC
LIMIT 10;
```

## üîí Seguridad

### RLS Policies

Los logs tienen RLS habilitado con las siguientes pol√≠ticas:

```sql
-- Cualquiera puede crear logs (incluso sin auth)
CREATE POLICY "Logs insertable by anyone"
  ON system_logs FOR INSERT
  WITH CHECK (true);

-- Solo admins pueden ver logs
CREATE POLICY "Logs viewable by admins"
  ON system_logs FOR SELECT
  USING (
    EXISTS (
      SELECT 1 FROM admin_users
      WHERE user_id = auth.uid()
        AND role IN ('super_admin', 'admin')
    )
  );

-- Solo admins pueden eliminar logs
CREATE POLICY "Logs deletable by admins"
  ON system_logs FOR DELETE
  USING (
    EXISTS (
      SELECT 1 FROM admin_users
      WHERE user_id = auth.uid()
        AND role = 'super_admin'
    )
  );
```

## üö® Alertas (Opcional)

Puedes configurar alertas para logs cr√≠ticos:

```typescript
// Worker que monitorea logs fatales
export const alertOnFatal = inngest.createFunction(
  { id: 'alert-on-fatal' },
  { event: 'log/fatal' }, // Trigger manual
  async ({ event }) => {
    // Enviar email/Slack/etc.
    await sendSlackAlert({
      message: `üö® Fatal error: ${event.data.message}`,
      error: event.data.errorMessage,
      userId: event.data.userId
    })
  }
)

// En el logger, trigger el evento
if (level === 'fatal') {
  await inngest.send({
    name: 'log/fatal',
    data: entry
  })
}
```

## üìä M√©tricas Recomendadas

Monitorear estos KPIs en el dashboard:

1. **Error Rate** - % de logs error/fatal vs total
2. **Top Errors** - Errores m√°s frecuentes en √∫ltimas 24h
3. **Performance** - Operaciones m√°s lentas (durationMs)
4. **User Errors** - Usuarios con m√°s errores
5. **Source Distribution** - % de logs por source

## üîÑ Migraci√≥n desde Sentry/PostHog

Si ya usas Sentry o PostHog:

1. ‚úÖ Mant√©n ambos sistemas en paralelo por 1 semana
2. ‚úÖ Compara volumen y calidad de logs
3. ‚úÖ Verifica que el dashboard cubra tus necesidades
4. ‚úÖ Elimina Sentry/PostHog cuando est√©s confiado

### Mapeo de Sentry a SystemLogger

```typescript
// Antes (Sentry)
Sentry.captureException(error)
Sentry.captureMessage('User logged in', 'info')
Sentry.setUser({ id: userId })

// Despu√©s (SystemLogger)
systemLogger.error('Error description', error)
systemLogger.info('User logged in')
systemLogger.setUserId(userId)
```

## üí∞ Estimaci√≥n de Costos

### Almacenamiento
- **1 log** ‚âà 500 bytes promedio
- **100,000 logs/d√≠a** ‚âà 50 MB/d√≠a ‚âà 1.5 GB/mes
- **Supabase Free Tier** = 500 MB database
- **Supabase Pro ($25/mes)** = 8 GB database

Con limpieza de logs > 30 d√≠as:
- **100,000 logs/d√≠a** ‚Üí ~45 GB m√°ximo
- Cabe en Supabase Pro sin problemas

### Comparaci√≥n con Sentry

| Servicio       | Costo/mes  | Logs incluidos |
| -------------- | ---------- | -------------- |
| Sentry Team    | $26/mes    | 50,000 errors  |
| Sentry Business| $80/mes    | 100,000 errors |
| **Quoorum**    | **$0**     | **Ilimitado**  |

## üéØ Roadmap

- [ ] Worker autom√°tico de limpieza (cron diario)
- [ ] Sistema de alertas (Slack/Email para fatals)
- [ ] Dashboard con gr√°ficos de tendencias
- [ ] Rate limiting por IP para prevenir spam
- [ ] Compresi√≥n de logs antiguos
- [ ] B√∫squeda full-text con √≠ndices GIN
- [ ] Export a formatos adicionales (JSON, Parquet)

---

**Fecha de creaci√≥n:** 2026-01-13
**Versi√≥n:** 1.0.0
**Autor:** Sistema de Logging Propio - Quoorum
